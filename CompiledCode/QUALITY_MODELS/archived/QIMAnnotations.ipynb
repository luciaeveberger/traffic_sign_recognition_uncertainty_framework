{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Python libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import skimage.morphology as morp\n",
    "from skimage.filters import rank\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "# is it using the GPU?\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "# Show current TensorFlow version\n",
    "tf.__version__\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unzip the \n",
    "import zipfile\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "qe1 = \"RAIN\"\n",
    "qe2 = \"DARKNESS\"\n",
    "qe3 = \"MOTIONBLUR\"\n",
    "qe4 = \"BACKLIGHTSUN\"\n",
    "\n",
    "model_file_paths = [\"TSD/h_files/deepCNN{}.h5\".format(qe1), \n",
    "                    \"TSD/h_files/deepCNN{}.h5\".format(qe2), \n",
    "                    \"TSD/h_files/deepCNN{}.h5\".format(qe3), \n",
    "                    \"TSD/h_files/deepCNN{}.h5\".format(qe4)\n",
    "                   ]\n",
    "\n",
    "quality_effect = \"LARGER_PROTOTYPE/\"\n",
    "zip_path =  \"TSD/LARGER_PROTOTYPE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BACKLIGHTSUN  DARKNESS  MOTIONBLUR  RAIN  SignType      Unnamed: 0  \\\n",
      "0           0.0      25.0        25.0   0.0        30    1557943525_0   \n",
      "1           0.0      25.0        25.0   0.0        26    1557943525_1   \n",
      "2           0.0      25.0        25.0   0.0        10   1557943525_10   \n",
      "3           0.0      25.0        25.0   0.0        22  1557943525_100   \n",
      "4           0.0      25.0        25.0   0.0        10  1557943525_101   \n",
      "\n",
      "                 class       detailed_class  \\\n",
      "0  MOTIONBLUR_DARKNESS  MOTIONBLUR_DARKNESS   \n",
      "1  MOTIONBLUR_DARKNESS  MOTIONBLUR_DARKNESS   \n",
      "2  MOTIONBLUR_DARKNESS  MOTIONBLUR_DARKNESS   \n",
      "3  MOTIONBLUR_DARKNESS  MOTIONBLUR_DARKNESS   \n",
      "4  MOTIONBLUR_DARKNESS  MOTIONBLUR_DARKNESS   \n",
      "\n",
      "                                       full_img_pth       hour  rain_sensor  \\\n",
      "0    1557943525_0_UC2_MOTIONBLUR-25_DARKNESS-25.png  20.108238     1.318375   \n",
      "1    1557943525_1_UC2_MOTIONBLUR-25_DARKNESS-25.png  22.524323     0.885584   \n",
      "2   1557943525_10_UC2_MOTIONBLUR-25_DARKNESS-25.png  18.098553     0.863455   \n",
      "3  1557943525_100_UC2_MOTIONBLUR-25_DARKNESS-25.png  21.245825     0.554225   \n",
      "4  1557943525_101_UC2_MOTIONBLUR-25_DARKNESS-25.png  19.576856     0.143492   \n",
      "\n",
      "   sun_altitude    velocity  \n",
      "0      1.791267   53.177698  \n",
      "1      4.496702  100.262587  \n",
      "2      0.643064   69.442950  \n",
      "3      2.081712   85.008078  \n",
      "4      3.124848   90.105790  \n",
      "Index(['BACKLIGHTSUN', 'DARKNESS', 'MOTIONBLUR', 'RAIN', 'SignType',\n",
      "       'Unnamed: 0', 'class', 'detailed_class', 'full_img_pth', 'hour',\n",
      "       'rain_sensor', 'sun_altitude', 'velocity'],\n",
      "      dtype='object')\n",
      "31400\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(zip_path + \"/{}/{}ALLcombined.csv\".format(quality_effect,quality_effect))\n",
    "zip_path = \"/Users/luciaeve/Documents/EMSE/KAISERSLAUTERN/THESIS/code/GTSRB_augmentations/Augmented/output_data/RANDOM_IMAGES/COMPILED_TESTSET/\"\n",
    "df = pd.read_csv(zip_path + \"/ALL_combined.csv\")\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    \"\"\"\n",
    "    Convert images to gray scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "def image_normalize(image):\n",
    "    \"\"\"\n",
    "    Normalize images to [0, 1] scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    image = np.divide(image, 255)\n",
    "    return image\n",
    "\n",
    "def local_histo_equalize(image):\n",
    "    \"\"\"\n",
    "    Apply local histogram equalization to grayscale images.\n",
    "        Parameters:\n",
    "            image: A grayscale image.\n",
    "    \"\"\"\n",
    "    kernel = morp.disk(30)\n",
    "    img_local = rank.equalize(image, selem=kernel)\n",
    "    return img_local\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Applying the preprocessing steps to the input data.\n",
    "        Parameters:\n",
    "            data: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    gray_images = list(map(gray_scale, data))\n",
    "    equalized_images = list(map(local_histo_equalize, gray_images))\n",
    "    n_training = data.shape\n",
    "    normalized_images = np.zeros((n_training[0], n_training[1], n_training[2]))\n",
    "    for i, img in enumerate(equalized_images):\n",
    "        normalized_images[i] = image_normalize(img)\n",
    "    normalized_images = normalized_images[..., None]\n",
    "    return normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def create_image_tensor(IMG_PTH):\n",
    "    img = image.load_img(IMG_PTH, target_size=(32, 32))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0) \n",
    "    img_tensor /= 255.  \n",
    "    new_image = img_tensor.reshape(img_tensor.shape[0], 3, 32, 32)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def create_predictions(model, image):\n",
    "    DEEP_CNN = list()  \n",
    "    model_input = create_image_tensor(image)\n",
    "    quality_model_prediction = model.predict(model_input)\n",
    "    prediction_label = quality_model_prediction.argmax()\n",
    "    DEEP_CNN.append(prediction_label)\n",
    "    \n",
    "    prediction_by_class = model.predict_proba(model_input) \n",
    "    prediction_prob = np.amax((prediction_by_class))\n",
    "    DEEP_CNN.append(prediction_prob)\n",
    "    return DEEP_CNN\n",
    "\n",
    "def evaluate_deep_CNN_images(input_model, new_test_images, deep=False):\n",
    "    if deep: \n",
    "        new_test_images = new_test_images.reshape(new_test_images.shape[0], 1, 32, 32)\n",
    "    y_prob = input_model.predict(new_test_images)\n",
    "    \n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    print(y_classes)\n",
    "    return y_classes,y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "RAIN_MODEL = load_model(model_file_paths[0])\n",
    "DARKNESS_MODEL = load_model(model_file_paths[1])\n",
    "MOTIONBLUR_MODEL = load_model(model_file_paths[2])\n",
    "BACKLIGHTSUN_MODEL = load_model(model_file_paths[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing images & processing\n"
     ]
    }
   ],
   "source": [
    "base_path  = zip_path\n",
    "\n",
    "def process_data(base_path, data_frame):\n",
    "    print(\"Resizing images & processing\")\n",
    "    in_data = []\n",
    "    cr_labels = []\n",
    "    for row, column in data_frame.iterrows():\n",
    "        img_id = column['full_img_pth']\n",
    "        directory = column['class']\n",
    "        img_pth = base_path + directory + \"/\" + img_id\n",
    "        if os.path.isfile(img_pth):\n",
    "            img = cv2.imread(img_pth)\n",
    "            img = cv2.resize(img, (32,32))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            in_data.append(img)\n",
    "            cr_labels.append(column['SignType'])\n",
    "        else: \n",
    "            print(\"IMAGE PATH NOT FOUND:{}\".format(img_pth))\n",
    "    return in_data, cr_labels\n",
    "## creates test images\n",
    "input_data, correct_labels = process_data(base_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_images = preprocess(np.asarray(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31400\n"
     ]
    }
   ],
   "source": [
    "print(len(new_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates the dataframe with prediction classes and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[1 1 0 ... 1 0 2]\n",
      "[0 0 0 ... 0 1 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "darkness_classes, darkness_prob = evaluate_deep_CNN_images(DARKNESS_MODEL,new_test_images, True)\n",
    "rain_classes, rain_prob = evaluate_deep_CNN_images(RAIN_MODEL,new_test_images, True)\n",
    "mb_classes, mb_prob = evaluate_deep_CNN_images(MOTIONBLUR_MODEL,new_test_images, True)\n",
    "backlight_classes, backlight_prob = evaluate_deep_CNN_images(BACKLIGHTSUN_MODEL,new_test_images, True)\n",
    "\n",
    "## adds new rows to the subset of the testing images \n",
    "df['DARKNESS_classes'] = darkness_classes\n",
    "df['RAIN_classes'] = rain_classes\n",
    "df['MOTIONBLUR_classes'] = mb_classes\n",
    "df['BACKLIGHTSUN_classes'] = backlight_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"TSD/DT_PROTOTYPE/data.csv\"\n",
    "df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
